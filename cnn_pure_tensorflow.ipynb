{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zMHj4SLErCRa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-21 08:39:07.711700: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-12-21 08:39:11.542756: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-12-21 08:39:11.543016: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-12-21 08:39:11.921681: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-21 08:39:12.961602: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-12-21 08:39:12.966807: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-21 08:39:21.729928: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# 1. Load and Prepare MNIST Data\n",
    "def load_mnist():\n",
    "    \"\"\"Loads and preprocesses the MNIST dataset.\"\"\"\n",
    "    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "    # Normalize pixel values to [0, 1]\n",
    "    x_train = x_train.astype(\"float32\") / 255.0\n",
    "    \n",
    "    x_test = x_test.astype(\"float32\") / 255.0\n",
    "\n",
    "    # Reshape to (batch_size, height, width, channels)\n",
    "    x_train = np.expand_dims(x_train, axis=-1)  # Add channel dimension\n",
    "    x_test = np.expand_dims(x_test, axis=-1)    # Add channel dimension\n",
    "\n",
    "    # Convert labels to one-hot encoding\n",
    "    y_train = tf.one_hot(y_train, depth=10)\n",
    "    y_test = tf.one_hot(y_test, depth=10)\n",
    "\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wP8VzKEdrERM"
   },
   "outputs": [],
   "source": [
    "# 2. Define Model Parameters\n",
    "LEARNING_RATE = 0.001\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 10\n",
    "INPUT_SHAPE = (28, 28, 1)  # MNIST input image shape\n",
    "NUM_CLASSES = 10  # 10 Digits 0-9\n",
    "\n",
    "\n",
    "# 3. Create TensorFlow Variables for Weights and Biases\n",
    "def initialize_weights_and_biases():\n",
    "    \"\"\"Initializes the weights and biases for the CNN.\"\"\"\n",
    "\n",
    "    # Convolutional Layer 1: 32 filters of size 3x3\n",
    "    W_conv1 = tf.Variable(tf.random.normal([3, 3, 1, 32], stddev=0.1))  # (height, width, input channels, output channels)\n",
    "    b_conv1 = tf.Variable(tf.random.normal([32], stddev=0.1))\n",
    "\n",
    "    # Convolutional Layer 2: 64 filters of size 3x3\n",
    "    W_conv2 = tf.Variable(tf.random.normal([3, 3, 32, 64], stddev=0.1))\n",
    "    b_conv2 = tf.Variable(tf.random.normal([64], stddev=0.1))\n",
    "\n",
    "    # Fully Connected Layer 1:\n",
    "    # Flattened output of the convolutional layers -> 128 neurons\n",
    "    W_fc1 = tf.Variable(tf.random.normal([7 * 7 * 64, 128], stddev=0.1))  # after pooling, size becomes 7x7x64\n",
    "    b_fc1 = tf.Variable(tf.random.normal([128], stddev=0.1))\n",
    "\n",
    "    # Fully Connected Layer 2 (Output Layer) : 128 neurons -> 10 classes\n",
    "    W_fc2 = tf.Variable(tf.random.normal([128, NUM_CLASSES], stddev=0.1))\n",
    "    b_fc2 = tf.Variable(tf.random.normal([NUM_CLASSES], stddev=0.1))\n",
    "\n",
    "    return W_conv1, b_conv1, W_conv2, b_conv2, W_fc1, b_fc1, W_fc2, b_fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p9xNqtpAuk_1"
   },
   "outputs": [],
   "source": [
    "# 4. Define the CNN Model\n",
    "def cnn_model(x, W_conv1, b_conv1, W_conv2, b_conv2, W_fc1, b_fc1, W_fc2, b_fc2):\n",
    "    \"\"\"Defines the CNN architecture.\"\"\"\n",
    "\n",
    "    # Convolutional Layer 1 with ReLU activation, max pool\n",
    "    conv1 = tf.nn.conv2d(x, W_conv1, strides=[1, 1, 1, 1], padding=\"SAME\")  # padding SAME to keep same height and width\n",
    "    conv1 = tf.nn.bias_add(conv1, b_conv1)\n",
    "    conv1 = tf.nn.relu(conv1)\n",
    "    pool1 = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"SAME\")  # Pooling reduces dimension\n",
    "\n",
    "    # Convolutional Layer 2 with ReLU activation, max pool\n",
    "    conv2 = tf.nn.conv2d(pool1, W_conv2, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "    conv2 = tf.nn.bias_add(conv2, b_conv2)\n",
    "    conv2 = tf.nn.relu(conv2)\n",
    "    pool2 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"SAME\")\n",
    "\n",
    "    # Flatten the output of pool2\n",
    "    flat_out = tf.reshape(pool2, [-1, 7 * 7 * 64])\n",
    "\n",
    "    # Fully Connected Layer 1 (dense layer) with ReLU activation\n",
    "    fc1 = tf.matmul(flat_out, W_fc1) + b_fc1\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "\n",
    "    # Fully Connected Layer 2 (Output Layer)\n",
    "    out = tf.matmul(fc1, W_fc2) + b_fc2\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ClB9ForzuooB"
   },
   "outputs": [],
   "source": [
    "# 5. Define Loss Function, Optimizer, and Accuracy\n",
    "def loss_function(logits, labels):\n",
    "    \"\"\"Defines the cross-entropy loss.\"\"\"\n",
    "    return tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bWkHu0UfuulV"
   },
   "outputs": [],
   "source": [
    "def accuracy(logits, labels):\n",
    "    \"\"\"Calculates the accuracy.\"\"\"\n",
    "    predictions = tf.argmax(logits, 1)\n",
    "    true_labels = tf.argmax(labels, 1)\n",
    "    correct_predictions = tf.equal(predictions, true_labels)\n",
    "    return tf.reduce_mean(tf.cast(correct_predictions, tf.float32))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "54ED_2D7uym9"
   },
   "outputs": [],
   "source": [
    "# 6. Training Loop\n",
    "def train(x_train, y_train, x_test, y_test, W_conv1, b_conv1, W_conv2, b_conv2, W_fc1, b_fc1, W_fc2, b_fc2):\n",
    "    \"\"\"Train the model and evaluate it.\"\"\"\n",
    "    num_batches = len(x_train) // BATCH_SIZE\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        for batch in range(num_batches):\n",
    "            batch_x = x_train[batch * BATCH_SIZE : (batch + 1) * BATCH_SIZE]\n",
    "            batch_y = y_train[batch * BATCH_SIZE : (batch + 1) * BATCH_SIZE]\n",
    "\n",
    "            # Calculate loss and apply gradients\n",
    "            with tf.GradientTape() as tape:\n",
    "                logits = cnn_model(batch_x, W_conv1, b_conv1, W_conv2, b_conv2, W_fc1, b_fc1, W_fc2, b_fc2)\n",
    "                loss = loss_function(logits, batch_y)\n",
    "\n",
    "            # Apply gradients\n",
    "            grads = tape.gradient(loss, [W_conv1, b_conv1, W_conv2, b_conv2, W_fc1, b_fc1, W_fc2, b_fc2])\n",
    "            tf.optimizers.Adam(learning_rate=LEARNING_RATE).apply_gradients(zip(grads, [W_conv1, b_conv1, W_conv2, b_conv2, W_fc1, b_fc1, W_fc2, b_fc2]))\n",
    "\n",
    "        # Evaluate on validation set after each epoch\n",
    "        logits = cnn_model(x_test, W_conv1, b_conv1, W_conv2, b_conv2, W_fc1, b_fc1, W_fc2, b_fc2)\n",
    "        acc = accuracy(logits, y_test)\n",
    "        print(f\"Epoch: {epoch+1}/{EPOCHS}, Validation Accuracy: {acc:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "drl4teG3u6l2",
    "outputId": "0b02ef6a-137c-4587-eaa2-7ffc44a33f1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10, Validation Accuracy: 0.9669\n",
      "Epoch: 2/10, Validation Accuracy: 0.9810\n",
      "Epoch: 3/10, Validation Accuracy: 0.9837\n",
      "Epoch: 4/10, Validation Accuracy: 0.9831\n",
      "Epoch: 5/10, Validation Accuracy: 0.9841\n",
      "Epoch: 6/10, Validation Accuracy: 0.9840\n",
      "Epoch: 7/10, Validation Accuracy: 0.9869\n",
      "Epoch: 8/10, Validation Accuracy: 0.9861\n",
      "Epoch: 9/10, Validation Accuracy: 0.9883\n",
      "Epoch: 10/10, Validation Accuracy: 0.9892\n",
      "Test Accuracy: 0.9892\n"
     ]
    }
   ],
   "source": [
    "# 7. Test the Model (Evaluation on Test Set)\n",
    "def test_model(x_test, y_test, W_conv1, b_conv1, W_conv2, b_conv2, W_fc1, b_fc1, W_fc2, b_fc2):\n",
    "    \"\"\"Evaluates the model on the test dataset.\"\"\"\n",
    "    logits = cnn_model(x_test, W_conv1, b_conv1, W_conv2, b_conv2, W_fc1, b_fc1, W_fc2, b_fc2)\n",
    "    acc = accuracy(logits, y_test)\n",
    "    print(f\"Test Accuracy: {acc:.4f}\")\n",
    "\n",
    "\n",
    "# --- Main Execution ----\n",
    "if __name__ == \"__main__\":\n",
    "    # Load and preprocess data\n",
    "    x_train, y_train, x_test, y_test = load_mnist()\n",
    "\n",
    "    # Initialize model parameters\n",
    "    W_conv1, b_conv1, W_conv2, b_conv2, W_fc1, b_fc1, W_fc2, b_fc2 = initialize_weights_and_biases()\n",
    "\n",
    "    # Train the model\n",
    "    train(x_train, y_train, x_test, y_test, W_conv1, b_conv1, W_conv2, b_conv2, W_fc1, b_fc1, W_fc2, b_fc2)\n",
    "\n",
    "    # Test the model after training\n",
    "    test_model(x_test, y_test, W_conv1, b_conv1, W_conv2, b_conv2, W_fc1, b_fc1, W_fc2, b_fc2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 92
    },
    "id": "EPFHcdJT2FjX",
    "outputId": "7ea35c80-d66e-4e6f-c6db-4bf45dd4febb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-9dc79e07-0792-4476-b376-40f16c0abb8e\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-9dc79e07-0792-4476-b376-40f16c0abb8e\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving images.png to images.png\n",
      "Uploaded image path: images.png\n"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "\n",
    "# Upload an image\n",
    "uploaded = files.upload()\n",
    "\n",
    "# The image file will be saved in the Colab environment\n",
    "# Check the uploaded file's name\n",
    "image_path = list(uploaded.keys())[0]\n",
    "print(f\"Uploaded image path: {image_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 469
    },
    "id": "pmp-V1Na2HZK",
    "outputId": "a7edc2e4-3c47-4c7e-d0cb-6cf025579bc6"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted digit: 3\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to preprocess and predict the image\n",
    "def predict_image(image_path, W_conv1, b_conv1, W_conv2, b_conv2, W_fc1, b_fc1, W_fc2, b_fc2):\n",
    "    # Load the image and convert it to grayscale\n",
    "    img = image.load_img(image_path, target_size=(28, 28), color_mode='grayscale')\n",
    "\n",
    "    # Convert the image to a numpy array and normalize it\n",
    "    img_array = image.img_to_array(img) / 255.0  # Normalize the image to [0, 1]\n",
    "\n",
    "    # Expand dimensions to match the input shape of the model (batch_size, height, width, channels)\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Shape becomes (1, 28, 28, 1)\n",
    "\n",
    "    # Make predictions using the model\n",
    "    logits = cnn_model(img_array, W_conv1, b_conv1, W_conv2, b_conv2, W_fc1, b_fc1, W_fc2, b_fc2)\n",
    "\n",
    "    # Get the predicted class\n",
    "    predicted_class = tf.argmax(logits, axis=1).numpy()[0]\n",
    "\n",
    "    return predicted_class\n",
    "\n",
    "# Visualize the uploaded image\n",
    "img = image.load_img(\"images.png\", target_size=(28, 28), color_mode='grayscale')\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.title(\"Uploaded Image\")\n",
    "plt.show()\n",
    "\n",
    "# Make a prediction for the uploaded image\n",
    "predicted_digit = predict_image(\"images.png\", W_conv1, b_conv1, W_conv2, b_conv2, W_fc1, b_fc1, W_fc2, b_fc2)\n",
    "print(f\"Predicted digit: {predicted_digit}\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
